  @{include("./../Commons/header-common.i")}
  <link rel='stylesheet' href='@{siteAddress}/assets/reset.css?v=3'>
  <link rel='stylesheet' href='@{siteAddress}/assets/index.css?v=3'>
  <link rel='canonical' href='@{siteAddress}/assorted-notes/landing-zones-aws-edition'>
  <title>Setting up a cloud landing zone - AWS edition</title>
</head>
<body class="my-content-page-1">
  <header>
  <div>
  <a href="@{siteAddress}/">Home</a>
  </div>
  </header>
  <main>
    <div class="left-column"></div>
    <div class="center-column">
    
    <h1>Setting up a cloud landing zone - AWS edition</h1>
    <p>
    The followin document describes, on a high level, how to setup AWS landing zone.
    <em>The text is living document.</em>
    </p>

    <h2>Step 1: The AWS Account</h2>
    <p>
    Your journey starts by creating an AWS Account.
    The AWS Account allows for access to AWS which provides computing resources and services on a pay-as-you-go basis.
    </p>

    <h3>1.1: Resources and Billing</h3>
    <p>AWS Accounts serve as the foundation for managing cloud resources and billing.
       As you start using AWS, your S3 Buckets, EC2 Instances, and other resources will accumulate usage costs.
       These resources are billed directly to the payment method linked to your AWS account.
       This is where AWS accounts also act as billing containers, ensuring that everything consumed is tied back to a single source of truth â€” your payment method.</p>

    <p>The core of every AWS account is the root user which is created during the setup of the AWS account.
    The root user holds unrestricted control over the entire AWS environment.
    The root user is granted full access to every resource within the account - like S3 buckets and EC2 instances - without any limitation
    </p>

    <h3>1.2: Sub-Accounting</h3>
    <p>One key practice to follow is using seperate AWS Accounts for different environments (e.g., development, test, stating, production) or for
       different tams within that organization. This reduces the risk of mistakes or security breaches by isolating environments and limiting the
       scope of potential damage.</p>
       
    <h3>1.3: Administrative Accounts</h3>
    <p>While the root user has unrestricted access, it is considered best practice to avoid using this account for daily operations.
       Instead administrative users should be created.</p>


    <h2>Step 2: Logging</h2>
    <p>Logging in its various forms is a way to <em>observe</em> your environments.
       The purpose of <em>observing</em> your environment are the various aspects of information security, design and development, and compliance.</p>

    <p>One usually distinguishes between three kinds of logs in AWS:</p>
    <dl>
      <dt>
      Account and API Activity
      </dt>
      <dd>
      Purpose: Who did what? We use AWS CloudTrail.
      </dd>
      
      <dt>
      Service  / Application Activity
      </dt>
      <dd>
      Purpose: What service (e.g., EC2, AWS Lambda) / application did what? We use CloudWatch.
      </dd>
      
      <dt>
      Network / Access Activity
      </dt>
      <dd>
      Purpose: Who connected from where?
      We use Virtual Private Cloud logs, Application Load Balancer logs, Elastic Load Balancer logs, S3 logs, etc.
      and usually store them in a dedicated S3 bucket; these logs then may be analyzed by other tools.
      </dd>
    </dl>

    <p>
    In general, it is advisable to somehow consolidate logs in a S3 bucket in a dedicated AWS account for an extended duration of time (e.g., 10 years);
    This approach can consolidate logs from multiple AWS Accounts into a single S3 bucket.
    this can be achieved by Lambad subscriptions for CloudWatch streams.
    <em>Important</em>: There are other methods to consolidate than AWS Lambda;
    each method and flavor of method must be investigated regarding its time-constraints (e.g., when do logs arrive and do they arrive reliably, etc.).
    </p>


    <h2>Step 2: Infrastructure as code, GIT Repository, and CI/CD</h2>
    <p>At this point, you are using the AWS CLI or the AWS web interface to setup things.
       Consider switching to infrastructure as code by installing Teraform or any other infrastructure as code, or IAC for short,
       on your local machine instead.</p>

    <p>Once you ensured that Teraform is working on your local machine and is properly configuring your
       cloud environments, you should immediatly backup the Teraform configurations to a Git Repository.
       This repository should be outside of your AWS accounts, e.g. on a GitHub or GitLab instance.</p>

    <p>Developers push updates to the Teraform configuration and hence to your cloud environments
       to that repository.</p>

    <p>It is now time to stop invoking Teraform manually from developer machines; rather, updates
       from the repository holding the Teraform configurations should trigger a CI/CD pipeline, e.g. GitHub Actions or GitLab CI/CD, 
       which executes Teraform.</p>

  </div>
  <div class="right-column"></div>
  </main>
  <footer>
    <div class="left-column"></div>
    <div class="center-column">

    </div>
    <div class="right-column">
      <div>Website maintained by @{siteAuthor}.</div>
      <div>Last modified on @{dayOfMonth()} @{monthName()} @{year()}.</div>
    </div>
  </footer>
</body>
</html>
